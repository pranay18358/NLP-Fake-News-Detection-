{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_News.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gud34WxsmdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2605a072-83bd-4bf1-cfe0-bdbcab7ea71a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 28.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 31.3MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 22.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 15.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 14.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 12.7MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 13.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 12.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 12.6MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 12.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 12.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=7a3ae9710952d180ff85accab3166be102c05645dc071eed0d78a7b596171ec8\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbSrLt4gKRzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6557706a-2550-4370-b5b4-df5f5a0d3d4d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu89b89zudCg"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwTqDztouikg"
      },
      "source": [
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqxPFgeQuiWD"
      },
      "source": [
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfbrAA4vKfeM"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/NLP_Fake_News\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo37P12lvamD"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgJxSpuqSlCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b7aaba-ac10-4e5e-89dc-744db0e8d252"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "answer.csv\t       English_Train_2.gsheet  submit.csv\n",
            "English_Test_2.gsheet  English_Train.gsheet    submit_test.csv\n",
            "English_Test.gsheet    English_Val.gsheet      submit_val_to_check_bert.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf8ZgjDhuqT_"
      },
      "source": [
        "worksheet = gc.open('English_Train').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "train_df = pd.DataFrame.from_records(rows)\n",
        "\n",
        "new_header = train_df.iloc[0] #grab the first row for the header\n",
        "train_df = train_df[1:] #take the data less the header row\n",
        "train_df.columns = new_header #set the header row as the df header\n",
        "\n",
        "label_news = {'real': 0, 'fake': 1}\n",
        "train_df['int_label'] = train_df['label'].map(label_news)\n",
        "train_df = train_df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8ReqL9CXJKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5603c052-774a-4687-959a-3e1e2aa7df32"
      },
      "source": [
        "train_df['tweet'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liU_vkz9SnTM"
      },
      "source": [
        "worksheet_val = gc.open('English_Val').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows_val = worksheet_val.get_all_values()\n",
        "val_df = pd.DataFrame.from_records(rows_val)\n",
        "\n",
        "val_new_header = val_df.iloc[0] #grab the first row for the header\n",
        "val_df = val_df[1:] #take the data less the header row\n",
        "val_df.columns = val_new_header #set the header row as the df header\n",
        "\n",
        "label_news = {'real': 0, 'fake': 1}\n",
        "val_df['int_label'] = val_df['label'].map(label_news)\n",
        "val_df = val_df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NpdUwbbXOi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b3d504-263c-4f19-fc3a-bc0129dc2c6e"
      },
      "source": [
        "val_df['int_label'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxmABiax-UCQ"
      },
      "source": [
        "worksheet_test = gc.open('English_Test_2').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows_test = worksheet_test.get_all_values()\n",
        "test_df = pd.DataFrame.from_records(rows_test)\n",
        "\n",
        "test_new_header = test_df.iloc[0] #grab the first row for the header\n",
        "test_df = test_df[1:] #take the data less the header row\n",
        "test_df.columns = test_new_header #set the header row as the df header\n",
        "#label_news = {'real': 0, 'fake': 1}\n",
        "test_df['int_label'] = list(range(1,len(test_df)+1))#test_df['label'].map(label_news)\n",
        "test_df = test_df.reset_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CME4MYa51b8B",
        "outputId": "6e6e3b8c-d72b-475c-9644-7eba72fd2f56"
      },
      "source": [
        "print(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     index    id                                              tweet  int_label\n",
            "0         1     1  Our daily update is published. States reported...          1\n",
            "1         2     2             Alfalfa is the only cure for COVID-19.          2\n",
            "2         3     3  President Trump Asked What He Would Do If He W...          3\n",
            "3         4     4  States reported 630 deaths. We are still seein...          4\n",
            "4         5     5  This is the sixth time a global health emergen...          5\n",
            "...     ...   ...                                                ...        ...\n",
            "2135   2136  2136  #CoronaVirusUpdates: State-wise details of Tot...       2136\n",
            "2136   2137  2137  Tonight 12(midnight) onwards Disaster Manageme...       2137\n",
            "2137   2138  2138  296 new cases of #COVID19Nigeria; Plateau-85 E...       2138\n",
            "2138   2139  2139  RT @CDCemergency: #DYK? @CDCgov’s One-Stop Sho...       2139\n",
            "2139   2140  2140  More than half of pregnant women recently admi...       2140\n",
            "\n",
            "[2140 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SA2yvNqxivf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8afb58-ecb9-46da-d94a-912ad7c16407"
      },
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S86x2N1CAXYV"
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kIoSakQx0zw"
      },
      "source": [
        "class FakeNewsDataset(Dataset):\n",
        "    \"\"\"Fake News Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, df, tokenizer, MAX_LEN):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with text and img name.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.csv_data = df\n",
        "        self.tokenizer_bert = tokenizer\n",
        "        self.MAX_LEN = MAX_LEN\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.csv_data.shape[0]\n",
        "    \n",
        "    def pre_processing_BERT(self, sent):\n",
        "        # Create empty lists to store outputs\n",
        "        input_ids = []\n",
        "        attention_mask = []\n",
        "        \n",
        "        encoded_sent = self.tokenizer_bert.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=self.MAX_LEN,                  # Max length to truncate/pad\n",
        "            padding='max_length',         # Pad sentence to max length\n",
        "            # return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True,      # Return attention mask\n",
        "            truncation=True\n",
        "            )\n",
        "        \n",
        "        input_ids = encoded_sent.get('input_ids')\n",
        "        attention_mask = encoded_sent.get('attention_mask')\n",
        "        \n",
        "        # Convert lists to tensors\n",
        "        input_ids = torch.tensor(input_ids)\n",
        "        attention_mask = torch.tensor(attention_mask)\n",
        "        \n",
        "        return input_ids, attention_mask\n",
        "     \n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        text = self.csv_data['tweet'][idx]\n",
        "        \n",
        "        tensor_input_id, tensor_input_mask = self.pre_processing_BERT(text)\n",
        "\n",
        "        label = self.csv_data['int_label'][idx]\n",
        "        label = torch.tensor(label)\n",
        "        sample = [tensor_input_id, tensor_input_mask, label]\n",
        "        # print(idx)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZqwptpn00lM"
      },
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aIvHnn70_fg"
      },
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 64\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the dataset\n",
        "transformed_dataset_train = FakeNewsDataset(train_df, tokenizer, MAX_LEN)\n",
        "\n",
        "transformed_dataset_val = FakeNewsDataset(val_df, tokenizer, MAX_LEN)\n",
        "transformed_dataset_test=FakeNewsDataset(test_df, tokenizer, MAX_LEN)\n",
        "\n",
        "train_dataloader = DataLoader(transformed_dataset_train, batch_size=16,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "val_dataloader = DataLoader(transformed_dataset_val, batch_size=16,\n",
        "                        shuffle=True, num_workers=0)\n",
        "test_dataloader = DataLoader(transformed_dataset_test, batch_size=16,\n",
        "                        shuffle=False, num_workers=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG6HmLbDZbo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96cd8fa-9f54-4c63-e98c-689ccd9dd441"
      },
      "source": [
        "for batch_idx, ans in enumerate(train_dataloader):\n",
        "    print('Batch idx {}, dataset index {}'.format(\n",
        "        batch_idx, ans[-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch idx 0, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 1, dataset index tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 2, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 3, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 4, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 5, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 6, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 7, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 8, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 9, dataset index tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 10, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 11, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 12, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 13, dataset index tensor([1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 14, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 15, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 16, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 17, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 18, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 19, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 20, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 21, dataset index tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 22, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 23, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 24, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 25, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 26, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 27, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 28, dataset index tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 29, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 30, dataset index tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 31, dataset index tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 32, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 33, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 34, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 35, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 36, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 37, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 38, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 39, dataset index tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 40, dataset index tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 41, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 42, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 43, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 44, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 45, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 46, dataset index tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 47, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 48, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 49, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 50, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 51, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 52, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 53, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 54, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 55, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 56, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 57, dataset index tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 58, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 59, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 60, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n",
            "Batch idx 61, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 62, dataset index tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 63, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 64, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 65, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 66, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 67, dataset index tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 68, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 69, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 70, dataset index tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 71, dataset index tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 72, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 73, dataset index tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 74, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 75, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 76, dataset index tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 77, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 78, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 79, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 80, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 81, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 82, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 83, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 84, dataset index tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 85, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 86, dataset index tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 87, dataset index tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 88, dataset index tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 89, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 90, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 91, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 92, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 93, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 94, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0])\n",
            "Batch idx 95, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 96, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 97, dataset index tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 98, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 99, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 100, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 101, dataset index tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1])\n",
            "Batch idx 102, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 103, dataset index tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 104, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 105, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 106, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 107, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 108, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 109, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 110, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 111, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 112, dataset index tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 113, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 114, dataset index tensor([1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 115, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 116, dataset index tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 117, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 118, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0])\n",
            "Batch idx 119, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 120, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 121, dataset index tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 122, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 123, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 124, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 125, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 126, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 127, dataset index tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 128, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 129, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 130, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 131, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 132, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 133, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 134, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 135, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 136, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 137, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 138, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 139, dataset index tensor([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 140, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 141, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 142, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 143, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 144, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 145, dataset index tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 146, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 147, dataset index tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 148, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 149, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 150, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 151, dataset index tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 152, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 153, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 154, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 155, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 156, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 157, dataset index tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 158, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 159, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 160, dataset index tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 161, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 162, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 163, dataset index tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 164, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 165, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 166, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 167, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 168, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 169, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 170, dataset index tensor([0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 171, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 172, dataset index tensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 173, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 174, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 175, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 176, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 177, dataset index tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 178, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 179, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 180, dataset index tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 181, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 182, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 183, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 184, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 185, dataset index tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 186, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 187, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 188, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 189, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 190, dataset index tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 191, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 192, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 193, dataset index tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 194, dataset index tensor([0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 195, dataset index tensor([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 196, dataset index tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 197, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 198, dataset index tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 199, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 200, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 201, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 202, dataset index tensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 203, dataset index tensor([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 204, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 205, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 206, dataset index tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 207, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 208, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 209, dataset index tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 210, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 211, dataset index tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 212, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 213, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 214, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 215, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 216, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 217, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 218, dataset index tensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 219, dataset index tensor([0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 220, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 221, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 222, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 223, dataset index tensor([1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 224, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 225, dataset index tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 226, dataset index tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 227, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 228, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 229, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 230, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 231, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 232, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 233, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 234, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 235, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 236, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 237, dataset index tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 238, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 239, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 240, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 241, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 242, dataset index tensor([1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 243, dataset index tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 244, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 245, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 246, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 247, dataset index tensor([1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 248, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 249, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 250, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 251, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 252, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 253, dataset index tensor([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 254, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 255, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 256, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 257, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 258, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 259, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 260, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 261, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 262, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 263, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 264, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 265, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 266, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 267, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 268, dataset index tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 269, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 270, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 271, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 272, dataset index tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 273, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 274, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 275, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 276, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 277, dataset index tensor([0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 278, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 279, dataset index tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 280, dataset index tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 281, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 282, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 283, dataset index tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 284, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 285, dataset index tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 286, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 287, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 288, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 289, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 290, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 291, dataset index tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 292, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 293, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 294, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 295, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 296, dataset index tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 297, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 298, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 299, dataset index tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 300, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 301, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 302, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 303, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 304, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 305, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 306, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 307, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 308, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 309, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 310, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 311, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 312, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 313, dataset index tensor([0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0])\n",
            "Batch idx 314, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 315, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 316, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 317, dataset index tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 318, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 319, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 320, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 321, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 322, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 323, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 324, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 325, dataset index tensor([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 326, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 327, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 328, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 329, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 330, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 331, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 332, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 333, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 334, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 335, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 336, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 337, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 338, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 339, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 340, dataset index tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1])\n",
            "Batch idx 341, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 342, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n",
            "Batch idx 343, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 344, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 345, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 346, dataset index tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 347, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 348, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 349, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 350, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 351, dataset index tensor([0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 352, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 353, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 354, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 355, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 356, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 357, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 358, dataset index tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 359, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 360, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 361, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 362, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 363, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 364, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 365, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 366, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 367, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 368, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 369, dataset index tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 370, dataset index tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 371, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 372, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 373, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 374, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 375, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 376, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 377, dataset index tensor([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 378, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 379, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 380, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 381, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 382, dataset index tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 383, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 384, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 385, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 386, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 387, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 388, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 389, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 390, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 391, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 392, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 393, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 394, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 395, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 396, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 397, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 398, dataset index tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 399, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 400, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 401, dataset index tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 402, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 403, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 404, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 405, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 406, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 407, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 408, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 409, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 410, dataset index tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 411, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 412, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 413, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 414, dataset index tensor([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 415, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 416, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 417, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 418, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 419, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 420, dataset index tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 421, dataset index tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 422, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 423, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 424, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 425, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 426, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 427, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 428, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 429, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 430, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 431, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 432, dataset index tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 433, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 434, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 435, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 436, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 437, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 438, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 439, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 440, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 441, dataset index tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 442, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 443, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 444, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 445, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 446, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 447, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 448, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 449, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 450, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 451, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 452, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 453, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 454, dataset index tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 455, dataset index tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 456, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 457, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 458, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 459, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 460, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 461, dataset index tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 462, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 463, dataset index tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 464, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 465, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 466, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 467, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 468, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0])\n",
            "Batch idx 469, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 470, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 471, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 472, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 473, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 474, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 475, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 476, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 477, dataset index tensor([0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 478, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 479, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 480, dataset index tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 481, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 482, dataset index tensor([0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 483, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 484, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 485, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 486, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 487, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 488, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 489, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 490, dataset index tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 491, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 492, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 493, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 494, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 495, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 496, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 497, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 498, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 499, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 500, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 501, dataset index tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 502, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 503, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 504, dataset index tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 505, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 506, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 507, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 508, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 509, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 510, dataset index tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 511, dataset index tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 512, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 513, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 514, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 515, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 516, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 517, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 518, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 519, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 520, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 521, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 522, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 523, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 524, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 525, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 526, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 527, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 528, dataset index tensor([1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 529, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 530, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 531, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 532, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 533, dataset index tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 534, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-j7B4K1JI4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d7a16f-ea26-4b89-b6f0-e5a8e6358066"
      },
      "source": [
        "for x in train_dataloader:\n",
        "    for t in x:\n",
        "        print(t.shape)\n",
        "        print(type(t))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 64])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16, 64])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([16])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkT1eRL71SrR"
      },
      "source": [
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDFgmdNq-8lg"
      },
      "source": [
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdDHqBRl-_se"
      },
      "source": [
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_82CSSX_FAp"
      },
      "source": [
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrdqK5Q_Gl5"
      },
      "source": [
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            # print(batch)\n",
        "            # print([type(t) for t in batch])\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvERg79j_jJa"
      },
      "source": [
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA_Iflk7Ya1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ac0397-a0a4-4ed6-c21f-8f94283dd43d"
      },
      "source": [
        "for batch_idx, ans in enumerate(train_dataloader):\n",
        "    print('Batch idx {}, dataset index {}'.format(\n",
        "        batch_idx, ans[-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch idx 0, dataset index tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 1, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 2, dataset index tensor([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 3, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 4, dataset index tensor([1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 5, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 6, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 7, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 8, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 9, dataset index tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 10, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 11, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 12, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 13, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 14, dataset index tensor([1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 15, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 16, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1])\n",
            "Batch idx 17, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 18, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 19, dataset index tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 20, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 21, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 22, dataset index tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 23, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 24, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 25, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 26, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 27, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 28, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 29, dataset index tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 30, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 31, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 32, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 33, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 34, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 35, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 36, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 37, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 38, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 39, dataset index tensor([1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 40, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 41, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 42, dataset index tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 43, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 44, dataset index tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 45, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 46, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 47, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 48, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 49, dataset index tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 50, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 51, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 52, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 53, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 54, dataset index tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 55, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 56, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0])\n",
            "Batch idx 57, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 58, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 59, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 60, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 61, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 62, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 63, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 64, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 65, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0])\n",
            "Batch idx 66, dataset index tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 67, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 68, dataset index tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 69, dataset index tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 70, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 71, dataset index tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 72, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 73, dataset index tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 74, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 75, dataset index tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 76, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 77, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 78, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 79, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 80, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 81, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 82, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 83, dataset index tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 84, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 85, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 86, dataset index tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 87, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 88, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 89, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 90, dataset index tensor([1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 91, dataset index tensor([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 92, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 93, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 94, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 95, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 96, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 97, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 98, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 99, dataset index tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 100, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 101, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 102, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 103, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 104, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 105, dataset index tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 106, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 107, dataset index tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 108, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 109, dataset index tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 110, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 111, dataset index tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 112, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 113, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 114, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 115, dataset index tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 116, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 117, dataset index tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 118, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 119, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 120, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 121, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 122, dataset index tensor([1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 123, dataset index tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 124, dataset index tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 125, dataset index tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 126, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 127, dataset index tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 128, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 129, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 130, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 131, dataset index tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 132, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 133, dataset index tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 134, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 135, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 136, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 137, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 138, dataset index tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 139, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 140, dataset index tensor([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 141, dataset index tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 142, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 143, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 144, dataset index tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 145, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 146, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])\n",
            "Batch idx 147, dataset index tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 148, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 149, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 150, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 151, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 152, dataset index tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 153, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 154, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 155, dataset index tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 156, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 157, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
            "Batch idx 158, dataset index tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 159, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 160, dataset index tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 161, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 162, dataset index tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 163, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 164, dataset index tensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 165, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 166, dataset index tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 167, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 168, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1])\n",
            "Batch idx 169, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 170, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 171, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 172, dataset index tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0])\n",
            "Batch idx 173, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 174, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0])\n",
            "Batch idx 175, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 176, dataset index tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 177, dataset index tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 178, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 179, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 180, dataset index tensor([1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 181, dataset index tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 182, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 183, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 184, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 185, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 186, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 187, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 188, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 189, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 190, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 191, dataset index tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 192, dataset index tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 193, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 194, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 195, dataset index tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 196, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 197, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 198, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0])\n",
            "Batch idx 199, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 200, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 201, dataset index tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 202, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 203, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 204, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 205, dataset index tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 206, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 207, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 208, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 209, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 210, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 211, dataset index tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 212, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 213, dataset index tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 214, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])\n",
            "Batch idx 215, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 216, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 217, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 218, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 219, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 220, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 221, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 222, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 223, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 224, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 225, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 226, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 227, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 228, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 229, dataset index tensor([1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 230, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 231, dataset index tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 232, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 233, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 234, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 235, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 236, dataset index tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 237, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 238, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 239, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 240, dataset index tensor([0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 241, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 242, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 243, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 244, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 245, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 246, dataset index tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 247, dataset index tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 248, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 249, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 250, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 251, dataset index tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 252, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 253, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 254, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 255, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 256, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 257, dataset index tensor([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 258, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 259, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 260, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 261, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 262, dataset index tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 263, dataset index tensor([1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 264, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 265, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 266, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 267, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 268, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 269, dataset index tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 270, dataset index tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 271, dataset index tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 272, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 273, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 274, dataset index tensor([0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 275, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 276, dataset index tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 277, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 278, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 279, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 280, dataset index tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 281, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 282, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 283, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 284, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 285, dataset index tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 286, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 287, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 288, dataset index tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 289, dataset index tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 290, dataset index tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 291, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 292, dataset index tensor([0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 293, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 294, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 295, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 296, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 297, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 298, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 299, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 300, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 301, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 302, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 303, dataset index tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 304, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 305, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 306, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 307, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 308, dataset index tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 309, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 310, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 311, dataset index tensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1])\n",
            "Batch idx 312, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 313, dataset index tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 314, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 315, dataset index tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])\n",
            "Batch idx 316, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 317, dataset index tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 318, dataset index tensor([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 319, dataset index tensor([0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 320, dataset index tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 321, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 322, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 323, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1])\n",
            "Batch idx 324, dataset index tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 325, dataset index tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 326, dataset index tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 327, dataset index tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 328, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 329, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 330, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 331, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 332, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 333, dataset index tensor([1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 334, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 335, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 336, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 337, dataset index tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 338, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 339, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 340, dataset index tensor([1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 341, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 342, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 343, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 344, dataset index tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 345, dataset index tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 346, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 347, dataset index tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 348, dataset index tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 349, dataset index tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 350, dataset index tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 351, dataset index tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 352, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 353, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 354, dataset index tensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 355, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0])\n",
            "Batch idx 356, dataset index tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 357, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 358, dataset index tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 359, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 360, dataset index tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 361, dataset index tensor([1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 362, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 363, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 364, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 365, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1])\n",
            "Batch idx 366, dataset index tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])\n",
            "Batch idx 367, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 368, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 369, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 370, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 371, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 372, dataset index tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 373, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 374, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 375, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 376, dataset index tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 377, dataset index tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 378, dataset index tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 379, dataset index tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 380, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 381, dataset index tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n",
            "Batch idx 382, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 383, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 384, dataset index tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 385, dataset index tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 386, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 387, dataset index tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 388, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 389, dataset index tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 390, dataset index tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 391, dataset index tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 392, dataset index tensor([1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 393, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 394, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 395, dataset index tensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 396, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 397, dataset index tensor([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 398, dataset index tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 399, dataset index tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 400, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 401, dataset index tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
            "Batch idx 402, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 403, dataset index tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 404, dataset index tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 405, dataset index tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 406, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 407, dataset index tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 408, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "Batch idx 409, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 410, dataset index tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 411, dataset index tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 412, dataset index tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 413, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 414, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0])\n",
            "Batch idx 415, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 416, dataset index tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 417, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 418, dataset index tensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0])\n",
            "Batch idx 419, dataset index tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1])\n",
            "Batch idx 420, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 421, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 422, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 423, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 424, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 425, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 426, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 427, dataset index tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 428, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
            "Batch idx 429, dataset index tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 430, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 431, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n",
            "Batch idx 432, dataset index tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 433, dataset index tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 434, dataset index tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 435, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 436, dataset index tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 437, dataset index tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 438, dataset index tensor([1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])\n",
            "Batch idx 439, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 440, dataset index tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 441, dataset index tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 442, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 443, dataset index tensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 444, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 445, dataset index tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
            "Batch idx 446, dataset index tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 447, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1])\n",
            "Batch idx 448, dataset index tensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0])\n",
            "Batch idx 449, dataset index tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 450, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 451, dataset index tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 452, dataset index tensor([1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0])\n",
            "Batch idx 453, dataset index tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 454, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 455, dataset index tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 456, dataset index tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1])\n",
            "Batch idx 457, dataset index tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1])\n",
            "Batch idx 458, dataset index tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 459, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch idx 460, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 461, dataset index tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 462, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1])\n",
            "Batch idx 463, dataset index tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 464, dataset index tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 465, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
            "Batch idx 466, dataset index tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0])\n",
            "Batch idx 467, dataset index tensor([0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
            "Batch idx 468, dataset index tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 469, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 470, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1])\n",
            "Batch idx 471, dataset index tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 472, dataset index tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1])\n",
            "Batch idx 473, dataset index tensor([1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 474, dataset index tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 475, dataset index tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 476, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 477, dataset index tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1])\n",
            "Batch idx 478, dataset index tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0])\n",
            "Batch idx 479, dataset index tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 480, dataset index tensor([1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 481, dataset index tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 482, dataset index tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 483, dataset index tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 484, dataset index tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 485, dataset index tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 486, dataset index tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 487, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 488, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1])\n",
            "Batch idx 489, dataset index tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 490, dataset index tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 491, dataset index tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n",
            "Batch idx 492, dataset index tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 493, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 494, dataset index tensor([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 495, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 496, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
            "Batch idx 497, dataset index tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 498, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 499, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "Batch idx 500, dataset index tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 501, dataset index tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 502, dataset index tensor([1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 503, dataset index tensor([0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1])\n",
            "Batch idx 504, dataset index tensor([0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 505, dataset index tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1])\n",
            "Batch idx 506, dataset index tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
            "Batch idx 507, dataset index tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
            "Batch idx 508, dataset index tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0])\n",
            "Batch idx 509, dataset index tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1])\n",
            "Batch idx 510, dataset index tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
            "Batch idx 511, dataset index tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1])\n",
            "Batch idx 512, dataset index tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])\n",
            "Batch idx 513, dataset index tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
            "Batch idx 514, dataset index tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0])\n",
            "Batch idx 515, dataset index tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n",
            "Batch idx 516, dataset index tensor([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1])\n",
            "Batch idx 517, dataset index tensor([1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 518, dataset index tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1])\n",
            "Batch idx 519, dataset index tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
            "Batch idx 520, dataset index tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1])\n",
            "Batch idx 521, dataset index tensor([1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1])\n",
            "Batch idx 522, dataset index tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n",
            "Batch idx 523, dataset index tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])\n",
            "Batch idx 524, dataset index tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0])\n",
            "Batch idx 525, dataset index tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1])\n",
            "Batch idx 526, dataset index tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
            "Batch idx 527, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1])\n",
            "Batch idx 528, dataset index tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1])\n",
            "Batch idx 529, dataset index tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0])\n",
            "Batch idx 530, dataset index tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0])\n",
            "Batch idx 531, dataset index tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0])\n",
            "Batch idx 532, dataset index tensor([1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0])\n",
            "Batch idx 533, dataset index tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1])\n",
            "Batch idx 534, dataset index tensor([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsDGS8_g_L8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f24a829-b7a5-4073-f436-4b0a82410dfc"
      },
      "source": [
        "## Training \n",
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.488730   |     -      |     -     |   3.09   \n",
            "   1    |   40    |   0.269039   |     -      |     -     |   2.95   \n",
            "   1    |   60    |   0.253583   |     -      |     -     |   2.94   \n",
            "   1    |   80    |   0.250061   |     -      |     -     |   3.03   \n",
            "   1    |   100   |   0.322083   |     -      |     -     |   2.93   \n",
            "   1    |   120   |   0.212990   |     -      |     -     |   2.99   \n",
            "   1    |   140   |   0.217332   |     -      |     -     |   2.97   \n",
            "   1    |   160   |   0.198653   |     -      |     -     |   2.96   \n",
            "   1    |   180   |   0.165036   |     -      |     -     |   2.97   \n",
            "   1    |   200   |   0.242497   |     -      |     -     |   2.94   \n",
            "   1    |   220   |   0.177028   |     -      |     -     |   2.91   \n",
            "   1    |   240   |   0.150108   |     -      |     -     |   2.96   \n",
            "   1    |   260   |   0.161016   |     -      |     -     |   2.92   \n",
            "   1    |   280   |   0.152531   |     -      |     -     |   2.92   \n",
            "   1    |   300   |   0.119171   |     -      |     -     |   2.94   \n",
            "   1    |   320   |   0.136760   |     -      |     -     |   2.90   \n",
            "   1    |   340   |   0.109983   |     -      |     -     |   2.92   \n",
            "   1    |   360   |   0.090305   |     -      |     -     |   2.91   \n",
            "   1    |   380   |   0.095616   |     -      |     -     |   2.92   \n",
            "   1    |   400   |   0.140300   |     -      |     -     |   2.94   \n",
            "   1    |   420   |   0.131178   |     -      |     -     |   2.90   \n",
            "   1    |   440   |   0.086495   |     -      |     -     |   2.88   \n",
            "   1    |   460   |   0.115877   |     -      |     -     |   2.92   \n",
            "   1    |   480   |   0.074375   |     -      |     -     |   2.89   \n",
            "   1    |   500   |   0.110989   |     -      |     -     |   2.93   \n",
            "   1    |   520   |   0.097547   |     -      |     -     |   2.91   \n",
            "   1    |   534   |   0.082397   |     -      |     -     |   2.04   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.034113   |     -      |     -     |   3.06   \n",
            "   2    |   40    |   0.033970   |     -      |     -     |   2.90   \n",
            "   2    |   60    |   0.033694   |     -      |     -     |   2.90   \n",
            "   2    |   80    |   0.025380   |     -      |     -     |   2.89   \n",
            "   2    |   100   |   0.019611   |     -      |     -     |   3.00   \n",
            "   2    |   120   |   0.051465   |     -      |     -     |   2.91   \n",
            "   2    |   140   |   0.073574   |     -      |     -     |   2.91   \n",
            "   2    |   160   |   0.027456   |     -      |     -     |   2.90   \n",
            "   2    |   180   |   0.010244   |     -      |     -     |   2.87   \n",
            "   2    |   200   |   0.073327   |     -      |     -     |   2.93   \n",
            "   2    |   220   |   0.063009   |     -      |     -     |   2.87   \n",
            "   2    |   240   |   0.038450   |     -      |     -     |   2.90   \n",
            "   2    |   260   |   0.043116   |     -      |     -     |   2.89   \n",
            "   2    |   280   |   0.005269   |     -      |     -     |   2.89   \n",
            "   2    |   300   |   0.075913   |     -      |     -     |   2.87   \n",
            "   2    |   320   |   0.052605   |     -      |     -     |   2.88   \n",
            "   2    |   340   |   0.036309   |     -      |     -     |   2.88   \n",
            "   2    |   360   |   0.062031   |     -      |     -     |   2.90   \n",
            "   2    |   380   |   0.088025   |     -      |     -     |   2.90   \n",
            "   2    |   400   |   0.066650   |     -      |     -     |   2.89   \n",
            "   2    |   420   |   0.032568   |     -      |     -     |   2.87   \n",
            "   2    |   440   |   0.058394   |     -      |     -     |   2.87   \n",
            "   2    |   460   |   0.058054   |     -      |     -     |   2.90   \n",
            "   2    |   480   |   0.046260   |     -      |     -     |   2.87   \n",
            "   2    |   500   |   0.019036   |     -      |     -     |   2.90   \n",
            "   2    |   520   |   0.014198   |     -      |     -     |   2.89   \n",
            "   2    |   534   |   0.009043   |     -      |     -     |   2.03   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DPSnda-A4s3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "67da4f6c-4dc0-488a-e55b-a08c95849f69"
      },
      "source": [
        "predictions=[]\n",
        "val_accuracy=[]\n",
        "for batch in test_dataloader:\n",
        "  \n",
        "  #print(batch)\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  print(batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_ids , b_mask = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs1 = bert_classifier(b_ids,b_mask)\n",
        "\n",
        "  logits1 = outputs1\n",
        "  logits2 = outputs1[0]\n",
        "\n",
        "  \n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  preds=torch.argmax(logits1,dim=1).flatten()\n",
        "  predictions.append(preds.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[  101,  2256,  3679,  ...,     0,     0,     0],\n",
            "        [  101, 22989, 10270,  ...,     0,     0,     0],\n",
            "        [  101,  2343,  8398,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2019,  5746,  ...,  1997,  3572,   102],\n",
            "        [  101,  2758,  1996,  ...,     0,     0,     0],\n",
            "        [  101,  4268,  3362,  ...,     0,     0,     0]], device='cuda:0'), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
            "       device='cuda:0'))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-fd7d35df4d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# Unpack the inputs from our dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mb_ids\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mb_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# Telling the model not to compute or store gradients, saving memory and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aREMsle0EJZ-"
      },
      "source": [
        "predictions[0].shape\n",
        "finaloutput=np.concatenate(predictions,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO16gGXBEMwA"
      },
      "source": [
        "df=pd.DataFrame(columns=['id','label'])\n",
        "df['id']=list(range(1,len(finaloutput)+1))\n",
        "df['label']=finaloutput.tolist()\n",
        "df.to_csv(\"submit_test_2.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}